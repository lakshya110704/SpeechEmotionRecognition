# ğŸ™ï¸ Speech Emotion Recognition Assistant

A smart assistant that listens to your voice and responds empathetically based on your emotion â€” powered by deep learning and audio signal processing.

---

## ğŸ” Features

- ğŸ§ Real-time emotion detection from microphone input
- ğŸ”Š Trained on the RAVDESS dataset (balanced)
- ğŸ§  CNN model with log-mel spectrogram + delta features
- ğŸ¤– Assistant-style responses to detected emotions
- ğŸ’¾ Model + label encoder saved for reuse

---

## ğŸ“¦ Tech Stack

- Python 3
- TensorFlow / Keras
- Librosa
- Sounddevice
- NumPy, Scikit-learn
- RAVDESS dataset (locally loaded)

---

## ğŸš€ How to Run

1. **Install dependencies**

```bash
pip install -r requirements.txt
```

2. **Train the model**

```bash
PYTHONPATH=. python src/train.py
```

3. **Run the assistant**

```bash
PYTHONPATH=. python src/predict.py
```

---

## ğŸ¯ Emotions Detected

- Neutral ğŸ˜
- Calm ğŸ˜Œ
- Happy ğŸ˜Š
- Sad ğŸ˜¢
- Angry ğŸ˜ 
- Fearful ğŸ˜¨
- Disgust ğŸ¤¢
- Surprised ğŸ˜²

---

## ğŸ“ Folder Structure

```
SpeechEmotionRecognition/
â”œâ”€â”€ data/               # RAVDESS .wav files
â”œâ”€â”€ models/             # Saved model (.keras) and encoder
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ load_data.py
â”‚   â”œâ”€â”€ extract_features.py
â”‚   â”œâ”€â”€ prepare_data.py
â”‚   â”œâ”€â”€ model.py
â”‚   â”œâ”€â”€ train.py
â”‚   â””â”€â”€ predict.py
â””â”€â”€ README.md
```

---

## ğŸ§  Future Ideas

- ğŸ›ï¸ Streamlit web UI
- ğŸ—£ï¸ Text-to-speech voice replies
- ğŸ“ˆ Confusion matrix / per-class metrics
- ğŸŒ REST API for integration

---

## ğŸ’¡ Credits

- Dataset: [RAVDESS - Ryerson Audio-Visual Database of Emotional Speech and Song](https://zenodo.org/record/1188976)
- Developed by [Lakshya Mehta](https://github.com/lakshya110704)